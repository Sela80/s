{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPk5MCsXdjhAfF9IDikqRrI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sela80/Data-Science-/blob/main/R%C3%A9ussite_des_%C3%A9tudiants_facteurs_et_perspectives.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OfT3iMSf3e-"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets --upgrade --quiet\n",
        "!pip install category_encoders\n",
        "!pip install category_encoders --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Importation des bibliothèques ---\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import plotly.express as px\n",
        "from category_encoders import CatBoostEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Modèles de régression\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor,RandomForestClassifier\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "DNYMbPYWf6wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/anassarfraz13/student-success-factors-and-insights\")"
      ],
      "metadata": {
        "id": "2VV3aZlsf8-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -2. Chargement et Inspection Initiale des Données ---\n",
        "# Charge le fichier CSV dans un DataFrame Pandas\n",
        "df1 = pd.read_csv('/content/student-success-factors-and-insights/StudentPerformanceFactors.csv')\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "U014uJCphqC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "b5GDtbJ7iBlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "S7Et31Ze1k1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df1.copy()"
      ],
      "metadata": {
        "id": "aENivQSz4aY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "Gfor7-rEiGa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['Teacher_Quality', 'Parental_Education_Level', 'Distance_from_Home']:\n",
        "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "muU79-_ji8oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "xjLUIo7ViKkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().transpose()"
      ],
      "metadata": {
        "id": "XXDA3jY9ibqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prétraitement"
      ],
      "metadata": {
        "id": "uRlIquduj3rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df.select_dtypes(include=['int64']).columns.drop('Exam_Score')\n",
        "cat_cols = df.select_dtypes(include=['object']).columns"
      ],
      "metadata": {
        "id": "cNGbmFO4kV3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.drop('Exam_Score', axis=1)\n",
        "y = df['Exam_Score']"
      ],
      "metadata": {
        "id": "J08UTahzlPbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), num_cols),\n",
        "    ('cat', CatBoostEncoder(), cat_cols)\n",
        "])"
      ],
      "metadata": {
        "id": "UNYRDZyTneeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train/test\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Taille train:\", x_train.shape)\n",
        "print(\"Taille test:\", x_test.shape)"
      ],
      "metadata": {
        "id": "RHmxV4q2npQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regression = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])"
      ],
      "metadata": {
        "id": "tp34SJdSoJpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "random_forest = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(random_state=42))\n",
        "])"
      ],
      "metadata": {
        "id": "15yCsgAzoOM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest_classifier = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])"
      ],
      "metadata": {
        "id": "HzLE3Gg-oZH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "models_to_evaluate = {\n",
        "    'Linear Regression': linear_regression,\n",
        "    'Random Forest': random_forest,\n",
        "    'Random Forest Classifier': random_forest_classifier\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models_to_evaluate.items():\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_test)\n",
        "    results[name] = {\n",
        "        'MAE': mean_absolute_error(y_test, y_pred),\n",
        "        'MSE': mean_squared_error(y_test, y_pred),\n",
        "        'R2': r2_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "for name, metrics in results.items():\n",
        "    print(f\"Metrics for {name}:\")\n",
        "    print(f\"MAE: {metrics['MAE']:.2f}\")\n",
        "    print(f\"MSE: {metrics['MSE']:.2f}\")\n",
        "    print(f\"R2: {metrics['R2']:.2f}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "D_8YLMnkopxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predire sur les bases de Train et Test"
      ],
      "metadata": {
        "id": "FedNqgw4rUUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predire les classes sur l'ensemble  de Train et Test\n",
        "y_train_pred = linear_regression.predict(x_train)\n",
        "y_test_pred = linear_regression.predict(x_test)"
      ],
      "metadata": {
        "id": "gh3I1XpJrWRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calcule les mesures de performance\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, RocCurveDisplay\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "train_MAE = mean_absolute_error(y_train, y_train_pred)\n",
        "train_MSE = mean_squared_error(y_train, y_train_pred)\n",
        "train_R2 = r2_score(y_train, y_train_pred)\n",
        "test_MAE = mean_absolute_error(y_test, y_test_pred)\n",
        "test_MSE = mean_squared_error(y_test, y_test_pred)\n",
        "test_R2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "#Créer le tableau d'évaluation de performance\n",
        "performance_Table = pd.DataFrame({\n",
        "    'DataSet': ['Train', 'Test'],\n",
        "    'MAE': [train_MAE, test_MAE],\n",
        "    'MSE': [train_MSE, test_MSE],\n",
        "    'R2': [train_R2, test_R2]\n",
        "})\n",
        "#Afficher le tableau d'évaluation de performance_Table\n",
        "print(performance_Table)"
      ],
      "metadata": {
        "id": "L9w7ql3LtBiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the performance table for plotting\n",
        "performance_melted = performance_Table.melt(id_vars='DataSet', var_name='Metric', value_name='Score')\n",
        "\n",
        "# Plot the performance metrics\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Metric', y='Score', hue='DataSet', data=performance_melted)\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.ylabel('Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TO-Z28yRwSdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70e92a9d"
      },
      "source": [
        "# Save the linear regression model\n",
        "joblib.dump(linear_regression, 'linear_regression_model.pkl')\n",
        "joblib.load('linear_regression_model.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('linear_regression_model.pkl')"
      ],
      "metadata": {
        "id": "b-m9px1Lwluy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
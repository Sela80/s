{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNrHPK2dcTbt6ojvjnmlbky",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sela80/s/blob/main/Ensemble_de_donn%C3%A9es_de_d%C3%A9tection_de_fraude.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#√Ä propos de l'ensemble de donn√©es\n",
        "L'ensemble de donn√©es contient les enregistrements des transactions financi√®res √† des fins de d√©tection de fraude. (6,3 millions d'enregistrements)\n",
        "Certains de ces enregistrements ont √©t√© signal√©s comme faux par les algorithmes existants.\n",
        "\n",
        "D‚Äôautres approches pourraient √™tre utilis√©es pour mettre en avant les propri√©t√©s des ing√©nieurs qui pourraient renforcer davantage les algorithmes de d√©tection de fraude et d√©couvrir o√π l‚Äôalgorithme existant pr√©sente des lacunes.\n",
        "\n",
        "ENCAISSEMENT : est le processus d'augmentation du solde du\n",
        "compte en payant en esp√®ces √† un commer√ßant.\n",
        "\n",
        "CASH-OUT : est le processus inverse du CASH-IN, il\n",
        "s'agit de retirer de l'argent chez un commer√ßant ce qui diminue\n",
        "le solde du compte.\n",
        "\n",
        "D√âBIT : il s'agit d'un processus similaire au CASH-OUT et implique l'envoi de l'argent du service d'argent mobile\n",
        "vers un compte bancaire.\n",
        "\n",
        "PAIEMENT : est le processus de paiement de biens ou de services aux commer√ßants qui diminue le solde du compte et augmente le solde du destinataire.\n",
        "\n",
        "TRANSFERT : est le processus d'envoi d'argent √† un autre utilisateur du service via la plateforme d'argent mobile"
      ],
      "metadata": {
        "id": "f0aZJyCZT1-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets --upgrade --quiet\n",
        "!pip install category_encoders\n",
        "!pip install category_encoders --upgrade --quiet"
      ],
      "metadata": {
        "id": "cQRCAHvHBgTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grLcWXEKSd-_"
      },
      "outputs": [],
      "source": [
        "# --- 1. Importation des biblioth√®ques ---\n",
        "\n",
        "# üîß Manipulation des donn√©es\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# üìä Visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ‚öôÔ∏è Pr√©traitement et split\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# üß† Mod√®les de classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# üß∞ Encodage et transformation\n",
        "from category_encoders import CatBoostEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# üìà √âvaluation\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "\n",
        "# ‚ö†Ô∏è Divers\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/amanalisiddiqui/fraud-detection-dataset\")"
      ],
      "metadata": {
        "id": "9bdci4LmBm6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -2. Chargement et Inspection Initiale des Donn√©es ---\n",
        "# Charge le fichier CSV dans un DataFrame Pandas\n",
        "\n",
        "df = pd.read_csv('/content/fraud-detection-dataset/AIML Dataset.csv')"
      ],
      "metadata": {
        "id": "jprfv4qlBpfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Affiche un titre pour la section\n",
        "print(\"=== Informations sur le Dataset ===\")\n",
        "# Affiche les dimensions du dataset (nombre de lignes, nombre de colonnes)\n",
        "print(f\"Dimensions: {df.shape}\")"
      ],
      "metadata": {
        "id": "1bWRiZN7BtvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Affiche les 5 premi√®res lignes du dataset pour un aper√ßu\n",
        "print(\"\\nPremi√®res lignes:\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "3EnWDbqGDVfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Affiche le type de donn√©es de chaque colonne (int, float, object, etc.)\n",
        "print(\"\\nTypes de donn√©es:\")\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "1q-VjkXzEMrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Affiche le nombre de valeurs manquantes pour chaque colonne\n",
        "print(\"\\nValeurs manquantes:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "T8d2ZWGIERI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R√©sum√© statistique\n",
        "\n",
        "df.describe().transpose()"
      ],
      "metadata": {
        "id": "DEPbsdwLEYXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Affiche la distribution de la variable cible 'charges'\n",
        "print(\"\\nDistribution de la variable cible 'isFraud':\")\n",
        "print(df['isFraud'].value_counts())"
      ],
      "metadata": {
        "id": "xk8-VITXEeyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#-- 2.Visualisons"
      ],
      "metadata": {
        "id": "SiTkiai9EuCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['nameOrig', 'nameDest', 'step'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "yDlE2MZtMNd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df.copy()"
      ],
      "metadata": {
        "id": "C2vNQlgKErqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Num_cols=df1.select_dtypes(include=['int64','float64']).columns\n",
        "Cat_cols=df1.select_dtypes(include=['object']).columns"
      ],
      "metadata": {
        "id": "bly2VBE4Fm5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(11, 8))\n",
        "# Calcule la matrice de corr√©lation entre toutes les features\n",
        "correlation_matrix = df1[Num_cols].corr()\n",
        "# Affiche la matrice sous forme de heatmap (carte de chaleur)\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
        "plt.title('Matrice de Corr√©lation des Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9tWkum8iFxk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution de la variable cible 'isFraud\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(df1['isFraud'], kde=True, bins=50)\n",
        "plt.title('Distribution de la variable cible isFraud')\n",
        "plt.xlabel('isFraud ')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dw8XXO63H9-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- 3. Pr√©traitement des Donn√©es ---\n"
      ],
      "metadata": {
        "id": "30PE0-NKIeby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selection des variables num√©riques et cat√©gorielles sans la variable cible(isFraud)\n",
        "\n",
        "Num_col = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "Num_col.remove('isFraud')\n",
        "\n",
        "Cat_col = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(\"Numerical Columns (excluding isFraud):\", Num_col)\n",
        "print(\"Categorical Columns:\", Cat_col)"
      ],
      "metadata": {
        "id": "sVhhB0cdIjNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=df.drop('isFraud',axis=1)\n",
        "y=df['isFraud']"
      ],
      "metadata": {
        "id": "QWZCyQ22NYM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), Num_col),\n",
        "    ('cat', CatBoostEncoder(), Cat_col)\n",
        "])"
      ],
      "metadata": {
        "id": "KJ5p_hOsNhdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train/test\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Taille train:\", x_train.shape)\n",
        "print(\"Taille test:\", x_test.shape)"
      ],
      "metadata": {
        "id": "JdHGBcIUNy6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R√©gression_logistique = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LogisticRegression())\n",
        "])"
      ],
      "metadata": {
        "id": "2O-ImsX8N9nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KNN = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', KNeighborsClassifier())\n",
        "])"
      ],
      "metadata": {
        "id": "Atel6TpSQNg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DecisionTreeRegressor = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', DecisionTreeClassifier())\n",
        "])"
      ],
      "metadata": {
        "id": "wtP8qHCyQfoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Random_Forest = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])"
      ],
      "metadata": {
        "id": "KrhL4lH4QsnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XGBClassifier= Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', GradientBoostingClassifier())\n",
        "])"
      ],
      "metadata": {
        "id": "qBwJ5c-gbOp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "models_to_evaluate = {\n",
        "    'R√©gression_logistique': R√©gression_logistique,\n",
        "    'KNN': KNN,\n",
        "    'DecisionTreeRegressor': DecisionTreeRegressor,\n",
        "    'Random_Forest': Random_Forest,\n",
        "    'XGBClassifier': XGBClassifier\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "ro68PbpXQ9Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa692b1a"
      },
      "source": [
        "# --- 5. √âvaluation des mod√®les ---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c44605b0"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "\n",
        "print(\"\\n=== M√©triques d'√©valuation sur le Test Set ===\")\n",
        "\n",
        "for model_name, model in models_to_evaluate.items():\n",
        "    print(f\"\\n--- {model_name} ---\")\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_pred_proba = model.predict_proba(x_test)[:, 1] # For ROC-AUC\n",
        "\n",
        "    # Evaluate\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
        "\n",
        "    # Plot ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc_score(y_test, y_pred_proba):.4f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve for {model_name}')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(Random_Forest, 'Random_Forest.pkl')\n",
        "print('mod√®le Sauvegarde')"
      ],
      "metadata": {
        "id": "QGJiVgAxiXL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Apr√®s avoir entra√Æn√© votre mod√®le Random Forest\n",
        "with open('Random_Forest.pkl', 'wb') as f:\n",
        "    pickle.dump(Random_Forest, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "TrBAj0W4nd0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('Random_Forest.pkl')"
      ],
      "metadata": {
        "id": "fv1PVZ2FiaIH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}